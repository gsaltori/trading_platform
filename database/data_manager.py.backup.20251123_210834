# database/data_manager.py - FIXED VERSION
import pandas as pd
import numpy as np
from sqlalchemy import create_engine, text, MetaData, Table, Column, Integer, String, Float, DateTime
from sqlalchemy.orm import sessionmaker, declarative_base
import redis
import pickle
import zlib
from datetime import datetime, timedelta
import logging
from typing import Dict, List, Optional, Any
import json

logger = logging.getLogger(__name__)
Base = declarative_base()

class TradingData(Base):
    __tablename__ = 'trading_data'
    
    id = Column(Integer, primary_key=True)
    symbol = Column(String(50))
    timeframe = Column(String(10))
    timestamp = Column(DateTime)
    open = Column(Float)
    high = Column(Float)
    low = Column(Float)
    close = Column(Float)
    volume = Column(Float)
    spread = Column(Float)
    
    @classmethod
    def create_table(cls, engine):
        Base.metadata.create_all(engine)

class DataManager:
    def __init__(self, config):
        self.memory_cache = {}  # Cache en memoria como fallback
        self.config = config
        self.influx_available = False
        self.postgres_available = False
        self.redis_available = False
        self.setup_databases()
    
    def setup_databases(self):
        """Configura todas las conexiones a bases de datos"""
        # Flags de disponibilidad
        self.postgres_available = False
        self.influx_available = False
        self.redis_available = False
        
        # PostgreSQL
        try:
            self.pg_engine = create_engine(self.config.database.postgres_url)
            self.Session = sessionmaker(bind=self.pg_engine)
            TradingData.create_table(self.pg_engine)
            self.postgres_available = True
            logger.info("PostgreSQL connected successfully")
        except Exception as e:
            logger.warning(f"PostgreSQL connection failed: {e}")
            self.pg_engine = None
            self.Session = None
        
        # InfluxDB
        try:
            self.influx_client = InfluxDBClient(
                url=self.config.database.influx_url,
                token=self.config.database.influx_token,
                org=self.config.database.influx_org
            )
            self.write_api = self.influx_client.write_api(write_option=SYNCHRONOUS)
            self.query_api = self.influx_client.query_api()
            self.influx_available = True
            logger.info("InfluxDB connected successfully")
        except Exception as e:
            logger.warning(f"InfluxDB connection failed: {e}")
            self.influx_client = None
            self.write_api = None
            self.query_api = None
        
        # Redis
        try:
            self.redis_client = redis.Redis.from_url(
                self.config.database.redis_url,
                decode_responses=False
            )
            self.redis_client.ping()
            self.redis_available = True
            logger.info("Redis connected successfully")
        except Exception as e:
            logger.warning(f"Redis connection failed: {e}")
            self.redis_client = None
        
        logger.info(f"Database availability - Postgres: {self.postgres_available}, "
                   f"InfluxDB: {self.influx_available}, Redis: {self.redis_available}")

    def store_market_data(self, symbol: str, timeframe: str, data: pd.DataFrame):
        """Almacena datos de mercado en múltiples bases de datos"""
        stored_somewhere = False
        
        # PostgreSQL para consultas estructuradas
        if self.postgres_available:
            try:
                self._store_in_postgres(symbol, timeframe, data)
                stored_somewhere = True
            except Exception as e:
                logger.error(f"Error storing in PostgreSQL: {e}")
        
        # InfluxDB para análisis temporal
        if self.influx_available:
            try:
                self._store_in_influx(symbol, timeframe, data)
                stored_somewhere = True
            except Exception as e:
                logger.error(f"Error storing in InfluxDB: {e}")
        
        # Redis para cache (siempre intentar cachear si está disponible)
        if self.redis_available:
            try:
                self._store_in_redis(symbol, timeframe, data)
                stored_somewhere = True
            except Exception as e:
                logger.error(f"Error storing in Redis: {e}")
        
        if not stored_somewhere:
            logger.warning("Data was not stored in any database")
    
    def _store_in_postgres(self, symbol: str, timeframe: str, data: pd.DataFrame):
        """Almacena en PostgreSQL"""
        if not self.postgres_available or self.Session is None:
            return
        
        with self.Session() as session:
            for idx, row in data.iterrows():
                record = TradingData(
                    symbol=symbol,
                    timeframe=timeframe,
                    timestamp=idx,
                    open=row.get('open'),
                    high=row.get('high'),
                    low=row.get('low'),
                    close=row.get('close'),
                    volume=row.get('volume', 0),
                    spread=row.get('spread', 0)
                )
                session.merge(record)  # Upsert
            session.commit()
    
    def _store_in_influx(self, symbol: str, timeframe: str, data: pd.DataFrame):
        """Almacena en InfluxDB"""
        if not self.influx_available:
            return
        """Almacena en InfluxDB"""
        if not self.influx_available or self.write_api is None:
            return
        
        from influxdb_client import Point
        
        points = []
        for idx, row in data.iterrows():
            point = Point("market_data") \
                .tag("symbol", symbol) \
                .tag("timeframe", timeframe) \
                .field("open", float(row.get('open', 0))) \
                .field("high", float(row.get('high', 0))) \
                .field("low", float(row.get('low', 0))) \
                .field("close", float(row.get('close', 0))) \
                .field("volume", float(row.get('volume', 0))) \
                .time(idx)
            points.append(point)
        
        self.write_api.write(bucket="trading", record=points)
    
    def _store_in_redis(self, symbol: str, timeframe: str, data: pd.DataFrame):
        """Almacena en Redis con compresión"""
        if not self.redis_available:
            return
        """Almacena en Redis con compresión"""
        cache_key = f"market_data:{symbol}:{timeframe}"
        compressed_data = zlib.compress(pickle.dumps(data))
        self.redis_client.setex(cache_key, 3600, compressed_data)  # 1 hora
    
    def get_cached_data(self, symbol: str, timeframe: str) -> Optional[pd.DataFrame]:
        """Obtiene datos cacheados de Redis"""
        if not self.redis_available:
            return None
        """Obtiene datos cacheados de Redis"""
        if not self.redis_available:
            return None
        
        try:
            cache_key = f"market_data:{symbol}:{timeframe}"
            cached = self.redis_client.get(cache_key)
            if cached:
                return pickle.loads(zlib.decompress(cached))
        except Exception as e:
            logger.error(f"Error getting cached data: {e}")
        return None
    
    def store_strategy_result(self, strategy_name: str, result_data: Dict):
        """Almacena resultados de estrategias"""
        if not self.influx_available or self.write_api is None:
            logger.warning("Cannot store strategy result - InfluxDB not available")
            return
        
        try:
            from influxdb_client import Point
            
            # InfluxDB para métricas temporales
            point = Point("strategy_performance") \
                .tag("strategy", strategy_name) \
                .field("sharpe", result_data.get('sharpe', 0)) \
                .field("max_drawdown", result_data.get('max_drawdown', 0)) \
                .field("total_return", result_data.get('total_return', 0)) \
                .time(datetime.utcnow())
            
            self.write_api.write(bucket="trading", record=point)
            
        except Exception as e:
            logger.error(f"Error storing strategy result: {e}")
    
    def get_performance_history(self, strategy_name: str, days: int = 30) -> pd.DataFrame:
        """Obtiene historial de performance de una estrategia"""
        if not self.influx_available or self.query_api is None:
            logger.warning("Cannot get performance history - InfluxDB not available")
            return pd.DataFrame()
        
        try:
            query = f'''
            from(bucket: "trading")
            |> range(start: -{days}d)
            |> filter(fn: (r) => r._measurement == "strategy_performance")
            |> filter(fn: (r) => r.strategy == "{strategy_name}")
            |> pivot(rowKey:["_time"], columnKey: ["_field"], valueColumn: "_value")
            '''
            
            result = self.query_api.query_data_frame(query)
            if not result.empty:
                return result.set_index('_time')
        except Exception as e:
            logger.error(f"Error getting performance history: {e}")
        
        return pd.DataFrame()